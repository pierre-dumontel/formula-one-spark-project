{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPbNh+8wvgDRBfc2MKE3OKS"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install PySpark"
      ],
      "metadata": {
        "id": "qmlN_xWr8Yzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQUiPFCpuskn",
        "outputId": "804d66a9-a815-4a66-cb45-d1d36ea5d535"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 45 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 56.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845513 sha256=e5760341495ce787563017298262035f4876fe306fe60e04b12b31207711d547\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/59/f5/79a5bf931714dcd201b26025347785f087370a10a3329a899c\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "\n",
        "sc = pyspark.SparkContext()\n",
        "sql_sc = pyspark.SQLContext(sc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kJS1AfrutO0",
        "outputId": "d928925d-d973-40a6-bfac-a5cce7896681"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:114: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g2rygmLutMx",
        "outputId": "1f0ad0e8-9e82-44f4-8db1-8b075684c10c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, TimestampType, DateType, FloatType\n",
        "from pyspark.sql.functions import current_timestamp, lit, col, to_timestamp, concat"
      ],
      "metadata": {
        "id": "XhdhN4fsfOOt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = (pyspark.sql.SparkSession\n",
        "         .builder\n",
        "         .appName('FormulaOne')\n",
        "         .getOrCreate()\n",
        ")"
      ],
      "metadata": {
        "id": "5R3wx0FHuzYj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import datasets "
      ],
      "metadata": {
        "id": "bXpEB5qj8f6Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eswvK8dEtzxC",
        "outputId": "ed8c416d-c23f-4e65-b1c1-7618ad2a34dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 5836k  100 5836k    0     0  27.1M      0 --:--:-- --:--:-- --:--:-- 27.1M\n"
          ]
        }
      ],
      "source": [
        "!curl -O http://ergast.com/downloads/f1db_csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/f1db_csv.zip -d /content/f1_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cvTMuRIt6Vh",
        "outputId": "da7885e8-57e1-4f9e-8491-3b65bfebcab1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/f1db_csv.zip\n",
            "  inflating: /content/f1_datasets/circuits.csv  \n",
            "  inflating: /content/f1_datasets/constructor_results.csv  \n",
            "  inflating: /content/f1_datasets/constructors.csv  \n",
            "  inflating: /content/f1_datasets/constructor_standings.csv  \n",
            "  inflating: /content/f1_datasets/drivers.csv  \n",
            "  inflating: /content/f1_datasets/driver_standings.csv  \n",
            "  inflating: /content/f1_datasets/lap_times.csv  \n",
            "  inflating: /content/f1_datasets/pit_stops.csv  \n",
            "  inflating: /content/f1_datasets/qualifying.csv  \n",
            "  inflating: /content/f1_datasets/races.csv  \n",
            "  inflating: /content/f1_datasets/results.csv  \n",
            "  inflating: /content/f1_datasets/seasons.csv  \n",
            "  inflating: /content/f1_datasets/sprint_results.csv  \n",
            "  inflating: /content/f1_datasets/status.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/f1_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hjp8wQGSuYWa",
        "outputId": "db816c09-5ad2-41f8-fdc3-9bbc6aacefb1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 20M\n",
            "-rw-rw-r-- 1 root root 9.8K Oct 31 08:51 circuits.csv\n",
            "-rw-rw-r-- 1 root root 206K Oct 31 08:51 constructor_results.csv\n",
            "-rw-rw-r-- 1 root root  17K Oct 31 08:51 constructors.csv\n",
            "-rw-rw-r-- 1 root root 298K Oct 31 08:51 constructor_standings.csv\n",
            "-rw-rw-r-- 1 root root  92K Oct 31 08:51 drivers.csv\n",
            "-rw-rw-r-- 1 root root 837K Oct 31 08:51 driver_standings.csv\n",
            "-rw-rw-r-- 1 root root  16M Oct 31 08:51 lap_times.csv\n",
            "-rw-rw-r-- 1 root root 363K Oct 31 08:51 pit_stops.csv\n",
            "-rw-rw-r-- 1 root root 408K Oct 31 08:51 qualifying.csv\n",
            "-rw-rw-r-- 1 root root 151K Oct 31 08:51 races.csv\n",
            "-rw-rw-r-- 1 root root 1.6M Oct 31 08:51 results.csv\n",
            "-rw-rw-r-- 1 root root 4.4K Oct 31 08:51 seasons.csv\n",
            "-rw-r--r-- 1 root root 6.8K Oct 31 08:51 sprint_results.csv\n",
            "-rw-rw-r-- 1 root root 2.1K Oct 31 08:51 status.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ingestion"
      ],
      "metadata": {
        "id": "d_3R9qNnvX6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load circuits file, using InferSchema "
      ],
      "metadata": {
        "id": "LBHmwWw8kXKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "circuits_schema = StructType(fields=[StructField(\"circuitId\", IntegerType(), False),\n",
        "                                     StructField(\"circuitRef\", StringType(), True),\n",
        "                                     StructField(\"name\", StringType(), True),\n",
        "                                     StructField(\"location\", StringType(), True),\n",
        "                                     StructField(\"country\", StringType(), True),\n",
        "                                     StructField(\"lat\", DoubleType(), True),\n",
        "                                     StructField(\"lng\", DoubleType(), True),\n",
        "                                     StructField(\"alt\", IntegerType(), True),\n",
        "                                     StructField(\"url\", StringType(), True)\n",
        "])\n",
        "\n",
        "circuits_df = (spark.read\n",
        "               .schema(circuits_schema)\n",
        "               .csv('/content/f1_datasets/circuits.csv', sep=',', header = True)\n",
        ")\n",
        "\n",
        "circuits_selected_df = circuits_df.select(col(\"circuitId\"),col(\"circuitRef\"),col(\"name\"),col(\"location\"),col(\"country\"),\\\n",
        "                                          col(\"lat\"),col(\"lng\"),col(\"alt\"))\n",
        "\n",
        "circuits_renamed_df = circuits_selected_df.withColumnRenamed(\"circuitId\",\"circuit_id\")\\\n",
        ".withColumnRenamed(\"circuitRef\",\"circuit_ref\")\\\n",
        ".withColumnRenamed(\"lat\",\"latitude\")\\\n",
        ".withColumnRenamed(\"lng\",\"longitude\")\\\n",
        ".withColumnRenamed(\"alt\",\"altitude\")\n",
        "\n",
        "circuits_final_df = circuits_renamed_df.withColumn(\"ingestion_date\",current_timestamp())\\\n",
        ".withColumn(\"env\",lit(\"Production\"))"
      ],
      "metadata": {
        "id": "rOvllxRFcsJN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write data as parquet "
      ],
      "metadata": {
        "id": "1rM1yNytkgRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "circuits_df.write.mode(\"overwrite\").parquet(\"/content/f1_datasets/circuits\")\n",
        "circuits_parquet = spark.read.parquet(\"/content/f1_datasets/circuits\")"
      ],
      "metadata": {
        "id": "WVkouDEmfTdQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ingest races file"
      ],
      "metadata": {
        "id": "27CDMrhKmF_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "races_schema = StructType(fields=[StructField(\"raceId\", IntegerType(), False),\n",
        "                                     StructField(\"year\", IntegerType(), True),\n",
        "                                     StructField(\"round\", IntegerType(), True),\n",
        "                                     StructField(\"circuitId\", StringType(), True),\n",
        "                                     StructField(\"name\", StringType(), True),\n",
        "                                     StructField(\"date\", DateType(), True),\n",
        "                                     StructField(\"time\", StringType(), True),\n",
        "                                     StructField(\"url\", StringType(), True)\n",
        "])\n",
        "\n",
        "races_df = (spark.read\n",
        "               .schema(races_schema)\n",
        "               .csv('/content/f1_datasets/races.csv', sep=',', header = True)\n",
        ")\n",
        "\n",
        "races_with_df = (races_df\n",
        "                  .withColumn(\"race_timestamp\", to_timestamp(concat(col(\"date\"),lit(' '),col(\"time\")),'yyyy-MM-dd HH:mm:ss'))\n",
        "                  .withColumn(\"ingestion_date\",current_timestamp())\n",
        ")\n",
        "\n",
        "races_selected_df = (races_with_df.select(col(\"raceId\").alias(\"race_id\"),col(\"year\").alias(\"race_year\"),\n",
        "                                          col(\"round\"),col(\"circuitId\").alias(\"circuit_id\"),col(\"name\"),col(\"ingestion_date\"),col(\"race_timestamp\"))\n",
        ")\n",
        "\n",
        "races_selected_df.write.mode(\"overwrite\").parquet(\"/content/f1_datasets/races\")\n",
        "races_parquet = spark.read.parquet(\"/content/f1_datasets/races\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74nayWf1lYne",
        "outputId": "3978ca43-c875-4e6c-cef4-85e0950a8894"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+-----+----------+--------------------+--------------------+-------------------+\n",
            "|race_id|race_year|round|circuit_id|                name|      ingestion_date|     race_timestamp|\n",
            "+-------+---------+-----+----------+--------------------+--------------------+-------------------+\n",
            "|      1|     2009|    1|         1|Australian Grand ...|2022-11-09 09:31:...|2009-03-29 06:00:00|\n",
            "|      2|     2009|    2|         2|Malaysian Grand Prix|2022-11-09 09:31:...|2009-04-05 09:00:00|\n",
            "|      3|     2009|    3|        17|  Chinese Grand Prix|2022-11-09 09:31:...|2009-04-19 07:00:00|\n",
            "|      4|     2009|    4|         3|  Bahrain Grand Prix|2022-11-09 09:31:...|2009-04-26 12:00:00|\n",
            "|      5|     2009|    5|         4|  Spanish Grand Prix|2022-11-09 09:31:...|2009-05-10 12:00:00|\n",
            "|      6|     2009|    6|         6|   Monaco Grand Prix|2022-11-09 09:31:...|2009-05-24 12:00:00|\n",
            "|      7|     2009|    7|         5|  Turkish Grand Prix|2022-11-09 09:31:...|2009-06-07 12:00:00|\n",
            "|      8|     2009|    8|         9|  British Grand Prix|2022-11-09 09:31:...|2009-06-21 12:00:00|\n",
            "|      9|     2009|    9|        20|   German Grand Prix|2022-11-09 09:31:...|2009-07-12 12:00:00|\n",
            "|     10|     2009|   10|        11|Hungarian Grand Prix|2022-11-09 09:31:...|2009-07-26 12:00:00|\n",
            "|     11|     2009|   11|        12| European Grand Prix|2022-11-09 09:31:...|2009-08-23 12:00:00|\n",
            "|     12|     2009|   12|        13|  Belgian Grand Prix|2022-11-09 09:31:...|2009-08-30 12:00:00|\n",
            "|     13|     2009|   13|        14|  Italian Grand Prix|2022-11-09 09:31:...|2009-09-13 12:00:00|\n",
            "|     14|     2009|   14|        15|Singapore Grand Prix|2022-11-09 09:31:...|2009-09-27 12:00:00|\n",
            "|     15|     2009|   15|        22| Japanese Grand Prix|2022-11-09 09:31:...|2009-10-04 05:00:00|\n",
            "|     16|     2009|   16|        18|Brazilian Grand Prix|2022-11-09 09:31:...|2009-10-18 16:00:00|\n",
            "|     17|     2009|   17|        24|Abu Dhabi Grand Prix|2022-11-09 09:31:...|2009-11-01 11:00:00|\n",
            "|     18|     2008|    1|         1|Australian Grand ...|2022-11-09 09:31:...|2008-03-16 04:30:00|\n",
            "|     19|     2008|    2|         2|Malaysian Grand Prix|2022-11-09 09:31:...|2008-03-23 07:00:00|\n",
            "|     20|     2008|    3|         3|  Bahrain Grand Prix|2022-11-09 09:31:...|2008-04-06 11:30:00|\n",
            "+-------+---------+-----+----------+--------------------+--------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add partition by "
      ],
      "metadata": {
        "id": "3pvosU1-31u-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "races_selected_df.write.mode(\"overwrite\").partitionBy('race_year').parquet(\"/content/f1_datasets/processed/races\")\n",
        "races_parquet = spark.read.parquet(\"/content/f1_datasets/processed/races\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFlNOSHpqoRM",
        "outputId": "7d7f1d6e-f6d8-4250-b783-b80f8bf3429e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+----------+--------------------+--------------------+-------------------+---------+\n",
            "|race_id|round|circuit_id|                name|      ingestion_date|     race_timestamp|race_year|\n",
            "+-------+-----+----------+--------------------+--------------------+-------------------+---------+\n",
            "|   1074|    1|         3|  Bahrain Grand Prix|2022-11-09 09:31:...|2022-03-20 15:00:00|     2022|\n",
            "|   1075|    2|        77|Saudi Arabian Gra...|2022-11-09 09:31:...|2022-03-27 17:00:00|     2022|\n",
            "|   1076|    3|         1|Australian Grand ...|2022-11-09 09:31:...|2022-04-10 05:00:00|     2022|\n",
            "|   1077|    4|        21|Emilia Romagna Gr...|2022-11-09 09:31:...|2022-04-24 13:00:00|     2022|\n",
            "|   1078|    5|        79|    Miami Grand Prix|2022-11-09 09:31:...|2022-05-08 19:30:00|     2022|\n",
            "|   1079|    6|         4|  Spanish Grand Prix|2022-11-09 09:31:...|2022-05-22 13:00:00|     2022|\n",
            "|   1080|    7|         6|   Monaco Grand Prix|2022-11-09 09:31:...|2022-05-29 13:00:00|     2022|\n",
            "|   1081|    8|        73|Azerbaijan Grand ...|2022-11-09 09:31:...|2022-06-12 11:00:00|     2022|\n",
            "|   1082|    9|         7| Canadian Grand Prix|2022-11-09 09:31:...|2022-06-19 18:00:00|     2022|\n",
            "|   1083|   10|         9|  British Grand Prix|2022-11-09 09:31:...|2022-07-03 14:00:00|     2022|\n",
            "|   1084|   11|        70| Austrian Grand Prix|2022-11-09 09:31:...|2022-07-10 13:00:00|     2022|\n",
            "|   1085|   12|        34|   French Grand Prix|2022-11-09 09:31:...|2022-07-24 13:00:00|     2022|\n",
            "|   1086|   13|        11|Hungarian Grand Prix|2022-11-09 09:31:...|2022-07-31 13:00:00|     2022|\n",
            "|   1087|   14|        13|  Belgian Grand Prix|2022-11-09 09:31:...|2022-08-28 13:00:00|     2022|\n",
            "|   1088|   15|        39|    Dutch Grand Prix|2022-11-09 09:31:...|2022-09-04 13:00:00|     2022|\n",
            "|   1089|   16|        14|  Italian Grand Prix|2022-11-09 09:31:...|2022-09-11 13:00:00|     2022|\n",
            "|   1091|   17|        15|Singapore Grand Prix|2022-11-09 09:31:...|2022-10-02 12:00:00|     2022|\n",
            "|   1092|   18|        22| Japanese Grand Prix|2022-11-09 09:31:...|2022-10-09 05:00:00|     2022|\n",
            "|   1093|   19|        69|United States Gra...|2022-11-09 09:31:...|2022-10-23 19:00:00|     2022|\n",
            "|   1094|   20|        32|Mexico City Grand...|2022-11-09 09:31:...|2022-10-30 20:00:00|     2022|\n",
            "+-------+-----+----------+--------------------+--------------------+-------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructors file"
      ],
      "metadata": {
        "id": "RiKFyzrUip7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "constructors_schema = StructType(fields=[StructField(\"constructorId\", StringType(), False),\n",
        "                                     StructField(\"constructorRef\", StringType(), True),\n",
        "                                     StructField(\"name\", StringType(), True),\n",
        "                                     StructField(\"nationality\", StringType(), True),\n",
        "                                     StructField(\"url\", StringType(), True)\n",
        "])\n",
        "\n",
        "constructors_df = (spark.read\n",
        "               .schema(constructors_schema)\n",
        "               .csv('/content/f1_datasets/constructors.csv', sep=',', header = True)\n",
        ")\n",
        "\n",
        "constructors_dropped_df = constructors_df.drop(\"url\")\n",
        "constructors_with_df = constructors_dropped_df.withColumn(\"ingestion_date\",current_timestamp())\n",
        "constructors_selected_df = (constructors_with_df.select(col(\"constructorId\").alias(\"constructor_id\"),\n",
        "                                                        col(\"constructorRef\").alias(\"constructor_ref\"),\n",
        "                                                        col(\"name\"),col(\"nationality\"),col(\"ingestion_date\"))\n",
        ")\n",
        "\n",
        "constructors_selected_df.write.mode(\"overwrite\").parquet(\"/content/f1_datasets/constructors\")\n",
        "constructors_parquet = spark.read.parquet(\"/content/f1_datasets/constructors\")"
      ],
      "metadata": {
        "id": "3tt8diWd4K1i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "522b9595-1f7d-4ea5-f35e-91598794cd98"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+---------------+-----------+-----------+--------------------+\n",
            "|constructor_id|constructor_ref|       name|nationality|      ingestion_date|\n",
            "+--------------+---------------+-----------+-----------+--------------------+\n",
            "|             1|        mclaren|    McLaren|    British|2022-11-09 09:31:...|\n",
            "|             2|     bmw_sauber| BMW Sauber|     German|2022-11-09 09:31:...|\n",
            "|             3|       williams|   Williams|    British|2022-11-09 09:31:...|\n",
            "|             4|        renault|    Renault|     French|2022-11-09 09:31:...|\n",
            "|             5|     toro_rosso| Toro Rosso|    Italian|2022-11-09 09:31:...|\n",
            "|             6|        ferrari|    Ferrari|    Italian|2022-11-09 09:31:...|\n",
            "|             7|         toyota|     Toyota|   Japanese|2022-11-09 09:31:...|\n",
            "|             8|    super_aguri|Super Aguri|   Japanese|2022-11-09 09:31:...|\n",
            "|             9|       red_bull|   Red Bull|   Austrian|2022-11-09 09:31:...|\n",
            "|            10|    force_india|Force India|     Indian|2022-11-09 09:31:...|\n",
            "|            11|          honda|      Honda|   Japanese|2022-11-09 09:31:...|\n",
            "|            12|         spyker|     Spyker|      Dutch|2022-11-09 09:31:...|\n",
            "|            13|            mf1|        MF1|    Russian|2022-11-09 09:31:...|\n",
            "|            14|     spyker_mf1| Spyker MF1|      Dutch|2022-11-09 09:31:...|\n",
            "|            15|         sauber|     Sauber|      Swiss|2022-11-09 09:31:...|\n",
            "|            16|            bar|        BAR|    British|2022-11-09 09:31:...|\n",
            "|            17|         jordan|     Jordan|      Irish|2022-11-09 09:31:...|\n",
            "|            18|        minardi|    Minardi|    Italian|2022-11-09 09:31:...|\n",
            "|            19|         jaguar|     Jaguar|    British|2022-11-09 09:31:...|\n",
            "|            20|          prost|      Prost|     French|2022-11-09 09:31:...|\n",
            "+--------------+---------------+-----------+-----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drivers file"
      ],
      "metadata": {
        "id": "Dm4ImQ9Vi-Og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drivers_schema = StructType(fields=[StructField(\"driverId\", IntegerType(), False),\n",
        "                                    StructField(\"driverRef\", StringType(), True),\n",
        "                                    StructField(\"number\", IntegerType(), True),\n",
        "                                    StructField(\"code\", StringType(), True),\n",
        "                                    StructField(\"forename\",StringType(),True),\n",
        "                                    StructField(\"surname\",StringType(),True),\n",
        "                                    StructField(\"dob\", DateType(), True),\n",
        "                                    StructField(\"nationality\", StringType(), True),\n",
        "                                    StructField(\"url\", StringType(), True)\n",
        "                                    ])\n",
        "\n",
        "drivers_df = (spark.read\n",
        "              .schema(drivers_schema)\n",
        "              .csv('/content/f1_datasets/drivers.csv', sep=',', header = True)\n",
        ")\n",
        "drivers_renamed_df = (drivers_df\n",
        "                      .withColumnRenamed(\"driverId\",\"driver_id\")\n",
        "                      .withColumnRenamed(\"driverRef\",\"driver_ref\")\n",
        "                      .withColumn(\"ingestion_date\",current_timestamp())\n",
        "                      .withColumn(\"name\",concat(col(\"forename\"),lit(\" \"), col(\"surname\")))\n",
        "                     )\n",
        "drivers_renamed_df.write.mode(\"overwrite\").parquet(\"/content/f1_datasets/drivers\")\n",
        "drivers_parquet = spark.read.parquet(\"/content/f1_datasets/drivers\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABcM2kDti8I9",
        "outputId": "0dcb19cd-390d-4933-c77a-fd31e86f98ad"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+------+----+---------+----------+----------+-----------+--------------------+--------------------+------------------+\n",
            "|driver_id|driver_ref|number|code| forename|   surname|       dob|nationality|                 url|      ingestion_date|              name|\n",
            "+---------+----------+------+----+---------+----------+----------+-----------+--------------------+--------------------+------------------+\n",
            "|        1|  hamilton|    44| HAM|    Lewis|  Hamilton|1985-01-07|    British|http://en.wikiped...|2022-11-09 09:31:...|    Lewis Hamilton|\n",
            "|        2|  heidfeld|  null| HEI|     Nick|  Heidfeld|1977-05-10|     German|http://en.wikiped...|2022-11-09 09:31:...|     Nick Heidfeld|\n",
            "|        3|   rosberg|     6| ROS|     Nico|   Rosberg|1985-06-27|     German|http://en.wikiped...|2022-11-09 09:31:...|      Nico Rosberg|\n",
            "|        4|    alonso|    14| ALO| Fernando|    Alonso|1981-07-29|    Spanish|http://en.wikiped...|2022-11-09 09:31:...|   Fernando Alonso|\n",
            "|        5|kovalainen|  null| KOV|   Heikki|Kovalainen|1981-10-19|    Finnish|http://en.wikiped...|2022-11-09 09:31:...| Heikki Kovalainen|\n",
            "|        6|  nakajima|  null| NAK|   Kazuki|  Nakajima|1985-01-11|   Japanese|http://en.wikiped...|2022-11-09 09:31:...|   Kazuki Nakajima|\n",
            "|        7|  bourdais|  null| BOU|Sébastien|  Bourdais|1979-02-28|     French|http://en.wikiped...|2022-11-09 09:31:...|Sébastien Bourdais|\n",
            "|        8| raikkonen|     7| RAI|     Kimi| Räikkönen|1979-10-17|    Finnish|http://en.wikiped...|2022-11-09 09:31:...|    Kimi Räikkönen|\n",
            "|        9|    kubica|    88| KUB|   Robert|    Kubica|1984-12-07|     Polish|http://en.wikiped...|2022-11-09 09:31:...|     Robert Kubica|\n",
            "|       10|     glock|  null| GLO|     Timo|     Glock|1982-03-18|     German|http://en.wikiped...|2022-11-09 09:31:...|        Timo Glock|\n",
            "|       11|      sato|  null| SAT|   Takuma|      Sato|1977-01-28|   Japanese|http://en.wikiped...|2022-11-09 09:31:...|       Takuma Sato|\n",
            "|       12| piquet_jr|  null| PIQ|   Nelson|Piquet Jr.|1985-07-25|  Brazilian|http://en.wikiped...|2022-11-09 09:31:...| Nelson Piquet Jr.|\n",
            "|       13|     massa|    19| MAS|   Felipe|     Massa|1981-04-25|  Brazilian|http://en.wikiped...|2022-11-09 09:31:...|      Felipe Massa|\n",
            "|       14| coulthard|  null| COU|    David| Coulthard|1971-03-27|    British|http://en.wikiped...|2022-11-09 09:31:...|   David Coulthard|\n",
            "|       15|    trulli|  null| TRU|    Jarno|    Trulli|1974-07-13|    Italian|http://en.wikiped...|2022-11-09 09:31:...|      Jarno Trulli|\n",
            "|       16|     sutil|    99| SUT|   Adrian|     Sutil|1983-01-11|     German|http://en.wikiped...|2022-11-09 09:31:...|      Adrian Sutil|\n",
            "|       17|    webber|  null| WEB|     Mark|    Webber|1976-08-27| Australian|http://en.wikiped...|2022-11-09 09:31:...|       Mark Webber|\n",
            "|       18|    button|    22| BUT|   Jenson|    Button|1980-01-19|    British|http://en.wikiped...|2022-11-09 09:31:...|     Jenson Button|\n",
            "|       19|  davidson|  null| DAV|  Anthony|  Davidson|1979-04-18|    British|http://en.wikiped...|2022-11-09 09:31:...|  Anthony Davidson|\n",
            "|       20|    vettel|     5| VET|Sebastian|    Vettel|1987-07-03|     German|http://en.wikiped...|2022-11-09 09:31:...|  Sebastian Vettel|\n",
            "+---------+----------+------+----+---------+----------+----------+-----------+--------------------+--------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results file"
      ],
      "metadata": {
        "id": "d1UHlKx0lDDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_schema = StructType(fields=[StructField(\"resultId\", IntegerType(), False),\n",
        "                                    StructField(\"raceId\", IntegerType(), True),\n",
        "                                    StructField(\"driverId\", IntegerType(), True),\n",
        "                                    StructField(\"constructorId\", IntegerType(), True),\n",
        "                                    StructField(\"number\", IntegerType(), True),\n",
        "                                    StructField(\"grid\", IntegerType(), True),\n",
        "                                    StructField(\"position\", IntegerType(), True),\n",
        "                                    StructField(\"positionText\", StringType(), True),\n",
        "                                    StructField(\"positionOrder\", IntegerType(), True),\n",
        "                                    StructField(\"points\", FloatType(), True),\n",
        "                                    StructField(\"laps\", IntegerType(), True),\n",
        "                                    StructField(\"time\", StringType(), True),\n",
        "                                    StructField(\"milliseconds\", IntegerType(), True),\n",
        "                                    StructField(\"fastestLap\", IntegerType(),True),\n",
        "                                    StructField(\"rank\", IntegerType(),True),\n",
        "                                    StructField(\"fastestLapTime\", StringType(), True),\n",
        "                                    StructField(\"fastestLapSpeed\", FloatType(),True),\n",
        "                                    StructField(\"statusId\", StringType(), True)\n",
        "                                    ])\n",
        "\n",
        "results_df = (spark.read\n",
        "              .schema(results_schema)\n",
        "              .csv('/content/f1_datasets/results.csv', sep=',', header = True)\n",
        ")\n",
        "\n",
        "results_clean_df = (results_df\n",
        "                    .drop(\"statusId\")\n",
        "                    .withColumnRenamed(\"resultId\",\"result_id\")\n",
        "                    .withColumnRenamed(\"raceId\",\"race_id\")\n",
        "                    .withColumnRenamed(\"driverId\",\"driver_id\")\n",
        "                    .withColumnRenamed(\"constructorId\",\"constructor_id\")\n",
        "                    .withColumnRenamed(\"positionText\",\"position_text\")\n",
        "                    .withColumnRenamed(\"positionOrder\",\"position_order\")\n",
        "                    .withColumnRenamed(\"fastestLap\",\"fastest_lap\")\n",
        "                    .withColumnRenamed(\"fastestLapTime\",\"fastest_lap_time\")\n",
        "                    .withColumnRenamed(\"fastestLapSpeed\",\"fastest_lap_speed\")\n",
        "                    .withColumn(\"ingestion_date\", current_timestamp())\n",
        "                    )\n",
        "\n",
        "results_clean_df.write.mode(\"overwrite\").partitionBy(\"race_id\").parquet(\"/content/f1_datasets/processed/results\")\n",
        "results_parquet = spark.read.parquet(\"/content/f1_datasets/processed/results\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwarIfHEjSJM",
        "outputId": "aa759e48-55f8-48ad-8d0d-f10af32c1a6e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+--------------+------+----+--------+-------------+--------------+------+----+----------+------------+-----------+----+----------------+-----------------+--------------------+-------+\n",
            "|result_id|driver_id|constructor_id|number|grid|position|position_text|position_order|points|laps|      time|milliseconds|fastest_lap|rank|fastest_lap_time|fastest_lap_speed|      ingestion_date|race_id|\n",
            "+---------+---------+--------------+------+----+--------+-------------+--------------+------+----+----------+------------+-----------+----+----------------+-----------------+--------------------+-------+\n",
            "|    19232|      657|           113|    14|  19|       1|            1|             1|   8.0| 200|3:49:17.27|    13757270|       null|null|              \\N|             null|2022-11-09 09:31:...|    800|\n",
            "|    19233|      525|           114|     9|   3|       2|            2|             2|   6.0| 200|  +1:09.95|    13827220|       null|null|              \\N|             null|2022-11-09 09:31:...|    800|\n",
            "|    19234|      658|           113|     2|   1|       3|            3|             3|   5.0| 200|  +1:19.73|    13837000|       null|null|              \\N|             null|2022-11-09 09:31:...|    800|\n",
            "|    19235|      526|           113|    34|  11|       4|            4|             4|   1.5| 200|  +2:52.68|    13929950|       null|null|              \\N|             null|2022-11-09 09:31:...|    800|\n",
            "|    19236|      673|           113|    73|  14|       5|            5|             5|   2.0| 200|  +3:24.55|    13961820|       null|null|              \\N|             null|2022-11-09 09:31:...|    800|\n",
            "|    19237|      615|           113|    77|  24|       6|            6|             6|   0.0| 200|  +3:47.55|    13984820|       null|null|              \\N|             null|2022-11-09 09:31:...|    800|\n",
            "|    19238|      528|           109|     7|   6|       7|            7|             7|   0.0| 200|  +4:13.35|    14010620|       null|null|              \\N|             null|2022-11-09 09:31:...|    800|\n",
            "|    19239|      555|           113|     5|  32|       8|            8|             8|   0.0| 200|  +5:01.17|    14058440|       null|null|              \\N|             null|2022-11-09 09:31:...|    800|\n",
            "|    19240|      674|           113|    28|  25|       9|            9|             9|   0.0| 200|  +7:07.24|    14184510|       null|null|              \\N|             null|2022-11-09 09:31:...|    800|\n",
            "|    19241|      655|           129|    24|  13|      10|           10|            10|   0.0| 200|  +7:07.69|    14184960|       null|null|              \\N|             null|2022-11-09 09:31:...|    800|\n",
            "|    19242|      656|           113|    45|  27|      11|           11|            11|   0.0| 200|  +8:22.19|    14259460|       null|null|              \\N|             null|2022-11-09 09:31:...|    800|\n",
            "|    19243|      521|           114|    98|   5|      12|           12|            12|   0.0| 199|        \\N|        null|       null|null|              \\N|             null|2022-11-09 09:31:...|    800|\n",
            "|    19244|      675|           114|    88|  22|      13|           13|            13|   0.0| 197|        \\N|        null|       null|null|              \\N|             null|2022-11-09 09:31:...|    800|\n",
            "|    19245|      628|           113|    17|   9|      14|           14|            14|   0.0| 197|        \\N|        null|       null|null|              \\N|             null|2022-11-09 09:31:...|    800|\n",
            "|    19246|      518|           113|    16|   8|      15|           15|            15|   0.0| 196|        \\N|        null|       null|null|              \\N|             null|2022-11-09 09:31:...|    800|\n",
            "|    19247|      679|           113|    32|  20|      16|           16|            16|   0.0| 194|        \\N|        null|       null|null|              \\N|             null|2022-11-09 09:31:...|    800|\n",
            "|    19248|      592|           136|    25|   7|      17|           17|            17|   0.0| 194|        \\N|        null|       null|null|              \\N|             null|2022-11-09 09:31:...|    800|\n",
            "|    19249|      596|           129|    27|  31|      18|           18|            18|   0.0| 193|        \\N|        null|       null|null|              \\N|             null|2022-11-09 09:31:...|    800|\n",
            "|    19250|      676|           113|    71|  33|      19|           19|            19|   0.0| 193|        \\N|        null|       null|null|              \\N|             null|2022-11-09 09:31:...|    800|\n",
            "|    19251|      611|           113|     1|  10|    null|            R|            20|   0.0| 191|        \\N|        null|       null|null|              \\N|             null|2022-11-09 09:31:...|    800|\n",
            "+---------+---------+--------------+------+----+--------+-------------+--------------+------+----+----------+------------+-----------+----+----------------+-----------------+--------------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pitstops file"
      ],
      "metadata": {
        "id": "Zix_tC-mr5ZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pitstops_schema = StructType(fields=[StructField(\"raceId\", IntegerType(), True),\n",
        "                                    StructField(\"driverId\", IntegerType(), True),\n",
        "                                    StructField(\"stop\", StringType(), False),\n",
        "                                    StructField(\"lap\", IntegerType(), True),\n",
        "                                    StructField(\"time\", StringType(), True),\n",
        "                                    StructField(\"duration\", StringType(), True),\n",
        "                                    StructField(\"milliseconds\", IntegerType(), True)\n",
        "])\n",
        "pitstops_df = (spark.read\n",
        "              .schema(pitstops_schema)\n",
        "              .csv('/content/f1_datasets/pit_stops.csv', sep=',', header = True)\n",
        ")\n",
        "\n",
        "pitstops_clean_df = (pitstops_df\n",
        "                    .withColumnRenamed(\"driverId\",\"driver_id\")\n",
        "                    .withColumnRenamed(\"raceId\",\"race_id\")\n",
        "                    .withColumn(\"ingestion_date\", current_timestamp())\n",
        "                    )\n",
        "\n",
        "pitstops_clean_df.write.mode(\"overwrite\").parquet(\"/content/f1_datasets/pit_stops\")\n",
        "pitstops_parquet = spark.read.parquet(\"/content/f1_datasets/pit_stops\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E6YT0Derr6p",
        "outputId": "74d14f4a-0216-4d45-f85f-b5d73f62f015"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+----+---+--------+--------+------------+--------------------+\n",
            "|race_id|driver_id|stop|lap|    time|duration|milliseconds|      ingestion_date|\n",
            "+-------+---------+----+---+--------+--------+------------+--------------------+\n",
            "|    841|      153|   1|  1|17:05:23|  26.898|       26898|2022-11-09 09:32:...|\n",
            "|    841|       30|   1|  1|17:05:52|  25.021|       25021|2022-11-09 09:32:...|\n",
            "|    841|       17|   1| 11|17:20:48|  23.426|       23426|2022-11-09 09:32:...|\n",
            "|    841|        4|   1| 12|17:22:34|  23.251|       23251|2022-11-09 09:32:...|\n",
            "|    841|       13|   1| 13|17:24:10|  23.842|       23842|2022-11-09 09:32:...|\n",
            "|    841|       22|   1| 13|17:24:29|  23.643|       23643|2022-11-09 09:32:...|\n",
            "|    841|       20|   1| 14|17:25:17|  22.603|       22603|2022-11-09 09:32:...|\n",
            "|    841|      814|   1| 14|17:26:03|  24.863|       24863|2022-11-09 09:32:...|\n",
            "|    841|      816|   1| 14|17:26:50|  25.259|       25259|2022-11-09 09:32:...|\n",
            "|    841|       67|   1| 15|17:27:34|  25.342|       25342|2022-11-09 09:32:...|\n",
            "|    841|        2|   1| 15|17:27:41|  22.994|       22994|2022-11-09 09:32:...|\n",
            "|    841|        1|   1| 16|17:28:24|  23.227|       23227|2022-11-09 09:32:...|\n",
            "|    841|      808|   1| 16|17:28:39|  24.535|       24535|2022-11-09 09:32:...|\n",
            "|    841|        3|   1| 16|17:29:00|  23.716|       23716|2022-11-09 09:32:...|\n",
            "|    841|      155|   1| 16|17:29:06|  24.064|       24064|2022-11-09 09:32:...|\n",
            "|    841|       16|   1| 16|17:29:08|  25.978|       25978|2022-11-09 09:32:...|\n",
            "|    841|       15|   1| 16|17:29:49|  24.899|       24899|2022-11-09 09:32:...|\n",
            "|    841|       18|   1| 17|17:30:24|  16.867|       16867|2022-11-09 09:32:...|\n",
            "|    841|      153|   2| 17|17:31:06|  24.463|       24463|2022-11-09 09:32:...|\n",
            "|    841|        5|   1| 17|17:31:11|  24.865|       24865|2022-11-09 09:32:...|\n",
            "+-------+---------+----+---+--------+--------+------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Laptimes file"
      ],
      "metadata": {
        "id": "IbqL0vQVyTtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "laptimes_schema = StructType(fields=[StructField(\"raceId\", IntegerType(), True),\n",
        "                                     StructField(\"driverId\", IntegerType(), True),\n",
        "                                     StructField(\"lap\", IntegerType(), True),\n",
        "                                     StructField(\"position\", IntegerType(), False),\n",
        "                                     StructField(\"time\", StringType(), True),\n",
        "                                     StructField(\"milliseconds\", IntegerType(), True)\n",
        "])\n",
        "laptimes_df = (spark.read\n",
        "              .schema(laptimes_schema)\n",
        "              .csv('/content/f1_datasets/lap_times.csv', sep=',', header = True)\n",
        ")\n",
        "\n",
        "laptimes_clean_df = (laptimes_df\n",
        "                    .withColumnRenamed(\"driverId\",\"driver_id\")\n",
        "                    .withColumnRenamed(\"raceId\",\"race_id\")\n",
        "                    .withColumn(\"ingestion_date\", current_timestamp())\n",
        "                    )\n",
        "\n",
        "laptimes_clean_df.write.mode(\"overwrite\").parquet(\"/content/f1_datasets/lap_times\")\n",
        "laptimes_parquet = spark.read.parquet(\"/content/f1_datasets/lap_times\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BK_qxlVuuiur",
        "outputId": "2cbae167-a0d1-4184-8131-b3bfb105c541"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+---+--------+--------+------------+--------------------+\n",
            "|race_id|driver_id|lap|position|    time|milliseconds|      ingestion_date|\n",
            "+-------+---------+---+--------+--------+------------+--------------------+\n",
            "|    841|       20|  1|       1|1:38.109|       98109|2022-11-09 09:32:...|\n",
            "|    841|       20|  2|       1|1:33.006|       93006|2022-11-09 09:32:...|\n",
            "|    841|       20|  3|       1|1:32.713|       92713|2022-11-09 09:32:...|\n",
            "|    841|       20|  4|       1|1:32.803|       92803|2022-11-09 09:32:...|\n",
            "|    841|       20|  5|       1|1:32.342|       92342|2022-11-09 09:32:...|\n",
            "|    841|       20|  6|       1|1:32.605|       92605|2022-11-09 09:32:...|\n",
            "|    841|       20|  7|       1|1:32.502|       92502|2022-11-09 09:32:...|\n",
            "|    841|       20|  8|       1|1:32.537|       92537|2022-11-09 09:32:...|\n",
            "|    841|       20|  9|       1|1:33.240|       93240|2022-11-09 09:32:...|\n",
            "|    841|       20| 10|       1|1:32.572|       92572|2022-11-09 09:32:...|\n",
            "|    841|       20| 11|       1|1:32.669|       92669|2022-11-09 09:32:...|\n",
            "|    841|       20| 12|       1|1:32.902|       92902|2022-11-09 09:32:...|\n",
            "|    841|       20| 13|       1|1:33.698|       93698|2022-11-09 09:32:...|\n",
            "|    841|       20| 14|       3|1:52.075|      112075|2022-11-09 09:32:...|\n",
            "|    841|       20| 15|       4|1:38.385|       98385|2022-11-09 09:32:...|\n",
            "|    841|       20| 16|       2|1:31.548|       91548|2022-11-09 09:32:...|\n",
            "|    841|       20| 17|       1|1:30.800|       90800|2022-11-09 09:32:...|\n",
            "|    841|       20| 18|       1|1:31.810|       91810|2022-11-09 09:32:...|\n",
            "|    841|       20| 19|       1|1:31.018|       91018|2022-11-09 09:32:...|\n",
            "|    841|       20| 20|       1|1:31.055|       91055|2022-11-09 09:32:...|\n",
            "+-------+---------+---+--------+--------+------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Qualifying file"
      ],
      "metadata": {
        "id": "tlediujZ0le4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qualifying_schema = StructType(fields=[\n",
        "    StructField(\"qualifyId\", IntegerType(), True),\n",
        "    StructField(\"raceId\", IntegerType(), True),\n",
        "    StructField(\"driverId\", IntegerType(), True),\n",
        "    StructField(\"constructorId\", IntegerType(), True),\n",
        "    StructField(\"number\", IntegerType(), True),\n",
        "    StructField(\"position\", IntegerType(), False),\n",
        "    StructField(\"q1\", StringType(), True),\n",
        "    StructField(\"q2\", StringType(), True),\n",
        "    StructField(\"q3\", StringType(), True)\n",
        "])\n",
        "qualifying_df = (spark.read\n",
        "              .schema(qualifying_schema)\n",
        "              .csv('/content/f1_datasets/qualifying.csv', sep=',', header = True)\n",
        ")\n",
        "\n",
        "qualifying_clean_df = (qualifying_df\n",
        "                       .withColumnRenamed(\"qualifyId\",\"qualify_id\")\n",
        "                       .withColumnRenamed(\"constructorId\",\"constructor_id\")\n",
        "                       .withColumnRenamed(\"driverId\",\"driver_id\")\n",
        "                       .withColumnRenamed(\"raceId\",\"race_id\")\n",
        "                       .withColumn(\"ingestion_date\", current_timestamp())\n",
        "                    )\n",
        "\n",
        "qualifying_clean_df.write.mode(\"overwrite\").parquet(\"/content/f1_datasets/qualifying\")\n",
        "qualifying_parquet = spark.read.parquet(\"/content/f1_datasets/qualifying\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uft2oVgG0UM0",
        "outputId": "3f09ea62-0fa4-414a-ac67-0ab841461c46"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+---------+--------------+------+--------+--------+--------+--------+--------------------+\n",
            "|qualify_id|race_id|driver_id|constructor_id|number|position|      q1|      q2|      q3|      ingestion_date|\n",
            "+----------+-------+---------+--------------+------+--------+--------+--------+--------+--------------------+\n",
            "|         1|     18|        1|             1|    22|       1|1:26.572|1:25.187|1:26.714|2022-11-09 09:32:...|\n",
            "|         2|     18|        9|             2|     4|       2|1:26.103|1:25.315|1:26.869|2022-11-09 09:32:...|\n",
            "|         3|     18|        5|             1|    23|       3|1:25.664|1:25.452|1:27.079|2022-11-09 09:32:...|\n",
            "|         4|     18|       13|             6|     2|       4|1:25.994|1:25.691|1:27.178|2022-11-09 09:32:...|\n",
            "|         5|     18|        2|             2|     3|       5|1:25.960|1:25.518|1:27.236|2022-11-09 09:32:...|\n",
            "|         6|     18|       15|             7|    11|       6|1:26.427|1:26.101|1:28.527|2022-11-09 09:32:...|\n",
            "|         7|     18|        3|             3|     7|       7|1:26.295|1:26.059|1:28.687|2022-11-09 09:32:...|\n",
            "|         8|     18|       14|             9|     9|       8|1:26.381|1:26.063|1:29.041|2022-11-09 09:32:...|\n",
            "|         9|     18|       10|             7|    12|       9|1:26.919|1:26.164|1:29.593|2022-11-09 09:32:...|\n",
            "|        10|     18|       20|             5|    15|      10|1:26.702|1:25.842|      \\N|2022-11-09 09:32:...|\n",
            "|        11|     18|       22|            11|    17|      11|1:26.369|1:26.173|      \\N|2022-11-09 09:32:...|\n",
            "|        12|     18|        4|             4|     5|      12|1:26.907|1:26.188|      \\N|2022-11-09 09:32:...|\n",
            "|        13|     18|       18|            11|    16|      13|1:26.712|1:26.259|      \\N|2022-11-09 09:32:...|\n",
            "|        14|     18|        6|             3|     8|      14|1:26.891|1:26.413|      \\N|2022-11-09 09:32:...|\n",
            "|        15|     18|       17|             9|    10|      15|1:26.914|      \\N|      \\N|2022-11-09 09:32:...|\n",
            "|        16|     18|        8|             6|     1|      16|1:26.140|      \\N|      \\N|2022-11-09 09:32:...|\n",
            "|        17|     18|       21|            10|    21|      17|1:27.207|      \\N|      \\N|2022-11-09 09:32:...|\n",
            "|        18|     18|        7|             5|    14|      18|1:27.446|      \\N|      \\N|2022-11-09 09:32:...|\n",
            "|        19|     18|       16|            10|    20|      19|1:27.859|      \\N|      \\N|2022-11-09 09:32:...|\n",
            "|        20|     18|       11|             8|    18|      20|1:28.208|      \\N|      \\N|2022-11-09 09:32:...|\n",
            "+----------+-------+---------+--------------+------+--------+--------+--------+--------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Notebook f1-csv-ingestion.ipynb has successfully been executed\")"
      ],
      "metadata": {
        "id": "IkgtMXFq2ry2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}